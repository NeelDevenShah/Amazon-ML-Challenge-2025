{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3933dc5",
   "metadata": {},
   "source": [
    "# üéØ Brand + Image Solution - Amazon ML Challenge 2025\n",
    "\n",
    "## Strategy:\n",
    "1. **Extract price-relevant text features**: Brand, quantity, pack count, quality indicators\n",
    "2. **Use miniCLIP for images**: Smaller model (512-dim), less noise\n",
    "3. **Simple ensemble**: LightGBM + XGBoost\n",
    "4. **No complex embeddings**: Focus on features that actually predict price\n",
    "\n",
    "**Expected**: 45-48% validation, 46-49% test (< 2% gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb84801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q lightgbm xgboost catboost scikit-learn pandas numpy pillow requests transformers torch torchvision fuzzywuzzy python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from fuzzywuzzy import process\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# For image processing\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üî• Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbfed04",
   "metadata": {},
   "source": [
    "## 1. Extract Price-Relevant Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_price_features(df):\n",
    "    \"\"\"\n",
    "    Extract features that ACTUALLY predict price:\n",
    "    - Brand (critical for pricing)\n",
    "    - Quantity + unit (normalized)\n",
    "    - Pack count\n",
    "    - Quality indicators (premium, organic, etc.)\n",
    "    - Size descriptors (small, large, XL, etc.)\n",
    "    \"\"\"\n",
    "    print(\"üîß Extracting price-relevant features...\")\n",
    "    \n",
    "    # ==================== BASIC EXTRACTION ====================\n",
    "    def safe_extract(text, pattern, default=\"\"):\n",
    "        if pd.isna(text):\n",
    "            return default\n",
    "        match = re.search(pattern, str(text), re.IGNORECASE)\n",
    "        return match.group(1).strip() if match else default\n",
    "    \n",
    "    # Extract item name and description\n",
    "    df['item_name'] = df['catalog_content'].apply(\n",
    "        lambda x: safe_extract(x, r\"Item Name:\\s*(.*?)(?=\\n|Bullet|Product|$)\")\n",
    "    )\n",
    "    df['product_desc'] = df['catalog_content'].apply(\n",
    "        lambda x: safe_extract(x, r\"Product Description:\\s*(.*?)(?=\\n|Value:|Unit:|$)\")\n",
    "    )\n",
    "    \n",
    "    # ==================== BRAND EXTRACTION (CRITICAL!) ====================\n",
    "    def extract_brand(item_name):\n",
    "        \"\"\"Extract brand - usually first capitalized word\"\"\"\n",
    "        words = str(item_name).split()\n",
    "        if not words:\n",
    "            return 'unknown'\n",
    "        \n",
    "        # Check first 3 words for brand\n",
    "        for word in words[:3]:\n",
    "            word_clean = re.sub(r'[^a-zA-Z]', '', word)  # Remove special chars\n",
    "            if len(word_clean) > 2 and word_clean[0].isupper():\n",
    "                return word_clean.lower()\n",
    "        \n",
    "        return words[0].lower() if words else 'unknown'\n",
    "    \n",
    "    df['brand'] = df['item_name'].apply(extract_brand)\n",
    "    df['brand_len'] = df['brand'].str.len()\n",
    "    \n",
    "    # ==================== QUANTITY EXTRACTION ====================\n",
    "    def extract_value(text):\n",
    "        match = re.search(r\"Value:\\s*([\\d.,]+)\", str(text), re.IGNORECASE)\n",
    "        if match:\n",
    "            try:\n",
    "                return float(match.group(1).replace(',', ''))\n",
    "            except:\n",
    "                return 0.0\n",
    "        return 0.0\n",
    "    \n",
    "    def extract_unit(text):\n",
    "        match = re.search(r\"Unit:\\s*([A-Za-z\\s]+)\", str(text), re.IGNORECASE)\n",
    "        return match.group(1).strip().lower() if match else 'unknown'\n",
    "    \n",
    "    df['value'] = df['catalog_content'].apply(extract_value)\n",
    "    df['unit'] = df['catalog_content'].apply(extract_unit)\n",
    "    \n",
    "    # Unit categorization\n",
    "    def categorize_unit(unit):\n",
    "        unit_lower = str(unit).lower()\n",
    "        if any(u in unit_lower for u in ['gram', 'kg', 'oz', 'ounce', 'pound', 'lb', 'mg']):\n",
    "            return 'weight'\n",
    "        elif any(u in unit_lower for u in ['ml', 'liter', 'litre', 'gallon', 'fl', 'fluid']):\n",
    "            return 'volume'\n",
    "        elif any(u in unit_lower for u in ['count', 'piece', 'each', 'unit']):\n",
    "            return 'count'\n",
    "        else:\n",
    "            return 'other'\n",
    "    \n",
    "    df['unit_category'] = df['unit'].apply(categorize_unit)\n",
    "    \n",
    "    # ==================== PACK COUNT ====================\n",
    "    def extract_pack_count(text):\n",
    "        patterns = [r'(\\d+)\\s*[-\\s]?pack', r'pack\\s*of\\s*(\\d+)', r'(\\d+)\\s*count']\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, str(text).lower())\n",
    "            if match:\n",
    "                try:\n",
    "                    return int(match.group(1))\n",
    "                except:\n",
    "                    pass\n",
    "        return 1\n",
    "    \n",
    "    df['pack_count'] = df['catalog_content'].apply(extract_pack_count)\n",
    "    df['total_quantity'] = df['value'] * df['pack_count']\n",
    "    \n",
    "    # ==================== QUALITY INDICATORS ====================\n",
    "    combined_text = (df['item_name'].fillna('') + ' ' + df['product_desc'].fillna('')).str.lower()\n",
    "    \n",
    "    quality_keywords = {\n",
    "        'organic': ['organic', 'bio'],\n",
    "        'premium': ['premium', 'deluxe', 'luxury', 'gourmet'],\n",
    "        'natural': ['natural', 'pure'],\n",
    "        'professional': ['professional', 'pro', 'industrial'],\n",
    "    }\n",
    "    \n",
    "    for key, terms in quality_keywords.items():\n",
    "        df[f'kw_{key}'] = combined_text.apply(\n",
    "            lambda x: int(any(term in str(x) for term in terms))\n",
    "        )\n",
    "    \n",
    "    # ==================== SIZE INDICATORS ====================\n",
    "    size_keywords = {\n",
    "        'small': ['small', 'mini', 'tiny'],\n",
    "        'large': ['large', 'xl', 'xxl', 'jumbo', 'family'],\n",
    "        'multi': ['pack', 'multi', 'bundle']\n",
    "    }\n",
    "    \n",
    "    for key, terms in size_keywords.items():\n",
    "        df[f'size_{key}'] = combined_text.apply(\n",
    "            lambda x: int(any(term in str(x) for term in terms))\n",
    "        )\n",
    "    \n",
    "    # ==================== TEXT STATISTICS ====================\n",
    "    df['text_len'] = df['catalog_content'].str.len()\n",
    "    df['word_count'] = combined_text.str.split().str.len()\n",
    "    df['digit_count'] = combined_text.str.count(r'\\d')\n",
    "    \n",
    "    # ==================== LOG TRANSFORMS ====================\n",
    "    df['log_value'] = np.log1p(df['value'].fillna(0))\n",
    "    df['sqrt_value'] = np.sqrt(df['value'].fillna(0))\n",
    "    df['log_pack'] = np.log1p(df['pack_count'])\n",
    "    df['log_total_qty'] = np.log1p(df['total_quantity'])\n",
    "    \n",
    "    print(f\"‚úÖ Extracted {len(df.columns)} features\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b00397a",
   "metadata": {},
   "source": [
    "## 2. miniCLIP Image Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e96a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_features_miniclip(df, max_images=None):\n",
    "    \"\"\"\n",
    "    Extract image features using openai/clip-vit-base-patch32 (miniCLIP)\n",
    "    - Smaller model (512-dim) vs large CLIP (768-dim)\n",
    "    - Less noise, faster processing\n",
    "    - Focus on product appearance, not semantic understanding\n",
    "    \"\"\"\n",
    "    print(\"\\nüñºÔ∏è Extracting miniCLIP image features...\")\n",
    "    \n",
    "    # Load miniCLIP model\n",
    "    print(\"   Loading miniCLIP model (openai/clip-vit-base-patch32)...\")\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"   Model loaded on {device}\")\n",
    "    print(f\"   Output dimension: 512\")\n",
    "    \n",
    "    # Filter valid image links\n",
    "    valid_links = df['image_link'].notna()\n",
    "    print(f\"   Total samples with images: {valid_links.sum()} / {len(df)}\")\n",
    "    \n",
    "    if max_images:\n",
    "        print(f\"   Processing only first {max_images} images for testing\")\n",
    "        valid_indices = df[valid_links].index[:max_images]\n",
    "    else:\n",
    "        valid_indices = df[valid_links].index\n",
    "    \n",
    "    # Initialize feature array\n",
    "    image_features = np.zeros((len(df), 512))\n",
    "    \n",
    "    # Process images in batches\n",
    "    batch_size = 32\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for i in range(0, len(valid_indices), batch_size):\n",
    "        batch_indices = valid_indices[i:i+batch_size]\n",
    "        batch_images = []\n",
    "        batch_valid_indices = []\n",
    "        \n",
    "        for idx in batch_indices:\n",
    "            try:\n",
    "                url = df.loc[idx, 'image_link']\n",
    "                response = requests.get(url, timeout=5)\n",
    "                image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "                batch_images.append(image)\n",
    "                batch_valid_indices.append(idx)\n",
    "            except Exception as e:\n",
    "                failed += 1\n",
    "                continue\n",
    "        \n",
    "        if batch_images:\n",
    "            try:\n",
    "                # Process batch\n",
    "                inputs = processor(images=batch_images, return_tensors=\"pt\", padding=True).to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = model.get_image_features(**inputs)\n",
    "                    features = outputs.cpu().numpy()\n",
    "                \n",
    "                # Store features\n",
    "                for j, idx in enumerate(batch_valid_indices):\n",
    "                    image_features[idx] = features[j]\n",
    "                    successful += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Batch processing error: {e}\")\n",
    "                failed += len(batch_images)\n",
    "        \n",
    "        if (i + batch_size) % 320 == 0:\n",
    "            print(f\"   Processed {i+batch_size}/{len(valid_indices)} | Success: {successful} | Failed: {failed}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Image feature extraction complete!\")\n",
    "    print(f\"   Successfully processed: {successful}\")\n",
    "    print(f\"   Failed: {failed}\")\n",
    "    print(f\"   Success rate: {successful/(successful+failed)*100:.1f}%\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    img_cols = [f'img_feat_{i}' for i in range(512)]\n",
    "    img_df = pd.DataFrame(image_features, columns=img_cols, index=df.index)\n",
    "    \n",
    "    return img_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eae00a1",
   "metadata": {},
   "source": [
    "## 3. Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ab10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üìÇ LOADING DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "train = pd.read_csv('dataset/train.csv', encoding='latin1')\n",
    "test = pd.read_csv('dataset/test.csv', encoding='latin1')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "\n",
    "# Extract text features\n",
    "train = extract_price_features(train)\n",
    "test = extract_price_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bb6c5d",
   "metadata": {},
   "source": [
    "## 4. Extract Image Features (Test on Sample First)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db17597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on 1000 samples first\n",
    "print(\"\\nüß™ Testing image extraction on 1000 train samples...\")\n",
    "train_img_sample = extract_image_features_miniclip(train, max_images=1000)\n",
    "\n",
    "print(\"\\nüí° If this works well (success rate > 80%), we'll process all images\")\n",
    "print(\"   Otherwise, we'll continue with text features only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11931ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide whether to use images based on sample test\n",
    "use_images = input(\"\\nDo you want to extract ALL image features? (yes/no): \").lower() == 'yes'\n",
    "\n",
    "if use_images:\n",
    "    print(\"\\nüñºÔ∏è Extracting ALL image features (this will take ~30-45 minutes)...\")\n",
    "    train_img_features = extract_image_features_miniclip(train)\n",
    "    test_img_features = extract_image_features_miniclip(test)\n",
    "else:\n",
    "    print(\"\\n‚è≠Ô∏è Skipping image extraction, using text features only\")\n",
    "    train_img_features = None\n",
    "    test_img_features = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00998b97",
   "metadata": {},
   "source": [
    "## 5. Out-of-Fold Brand Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364374b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîß OUT-OF-FOLD BRAND ENCODING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 5-fold OOF encoding\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "oof_brand_mean = np.zeros(len(train))\n",
    "oof_brand_freq = np.zeros(len(train))\n",
    "oof_unit_mean = np.zeros(len(train))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train)):\n",
    "    print(f\"Processing fold {fold+1}/5...\", end='\\r')\n",
    "    \n",
    "    train_fold = train.iloc[train_idx]\n",
    "    val_fold = train.iloc[val_idx]\n",
    "    \n",
    "    # Brand mean price\n",
    "    brand_mean = train_fold.groupby('brand')['price'].mean()\n",
    "    global_mean = train_fold['price'].mean()\n",
    "    oof_brand_mean[val_idx] = val_fold['brand'].map(brand_mean).fillna(global_mean).values\n",
    "    \n",
    "    # Brand frequency\n",
    "    brand_freq = train_fold['brand'].value_counts()\n",
    "    oof_brand_freq[val_idx] = val_fold['brand'].map(brand_freq).fillna(0).values\n",
    "    \n",
    "    # Unit mean price\n",
    "    unit_mean = train_fold.groupby('unit_category')['price'].mean()\n",
    "    oof_unit_mean[val_idx] = val_fold['unit_category'].map(unit_mean).fillna(global_mean).values\n",
    "\n",
    "print(\"Processing fold 5/5... ‚úÖ\")\n",
    "\n",
    "# Add to dataframe\n",
    "train['brand_mean_encoded'] = oof_brand_mean\n",
    "train['brand_freq_encoded'] = oof_brand_freq\n",
    "train['unit_mean_encoded'] = oof_unit_mean\n",
    "\n",
    "# For test, use full train statistics\n",
    "brand_mean_full = train.groupby('brand')['price'].mean()\n",
    "brand_freq_full = train['brand'].value_counts()\n",
    "unit_mean_full = train.groupby('unit_category')['price'].mean()\n",
    "global_mean_full = train['price'].mean()\n",
    "\n",
    "test['brand_mean_encoded'] = test['brand'].map(brand_mean_full).fillna(global_mean_full)\n",
    "test['brand_freq_encoded'] = test['brand'].map(brand_freq_full).fillna(0)\n",
    "test['unit_mean_encoded'] = test['unit_category'].map(unit_mean_full).fillna(global_mean_full)\n",
    "\n",
    "# Interaction features\n",
    "train['value_x_brand'] = train['value'] * train['brand_mean_encoded']\n",
    "test['value_x_brand'] = test['value'] * test['brand_mean_encoded']\n",
    "\n",
    "print(\"\\n‚úÖ OOF encoding complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125e2e6e",
   "metadata": {},
   "source": [
    "## 6. Prepare Features for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478411dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude non-feature columns\n",
    "exclude_cols = [\n",
    "    'sample_id', 'catalog_content', 'image_link', 'price',\n",
    "    'item_name', 'product_desc', 'unit', 'brand'\n",
    "]\n",
    "\n",
    "# Select numerical features\n",
    "num_feature_cols = [col for col in train.columns \n",
    "                    if col not in exclude_cols and not col.startswith('img_feat_')]\n",
    "\n",
    "print(f\"üìä Feature counts:\")\n",
    "print(f\"   Numerical features: {len(num_feature_cols)}\")\n",
    "\n",
    "# Prepare data\n",
    "X_num = train[num_feature_cols].fillna(0)\n",
    "y = train['price']\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = RobustScaler()\n",
    "X_num_scaled = scaler.fit_transform(X_num)\n",
    "\n",
    "# Combine with image features if available\n",
    "if use_images and train_img_features is not None:\n",
    "    X_combined = np.hstack([X_num_scaled, train_img_features.values])\n",
    "    print(f\"   Image features: 512\")\n",
    "    print(f\"   Total features: {X_combined.shape[1]}\")\n",
    "else:\n",
    "    X_combined = X_num_scaled\n",
    "    print(f\"   Total features: {X_combined.shape[1]} (text only)\")\n",
    "\n",
    "# Split for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_combined, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Log transform target\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_val_log = np.log1p(y_val)\n",
    "\n",
    "print(f\"\\nüìä Training set: {X_train.shape}\")\n",
    "print(f\"üìä Validation set: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab59a6e4",
   "metadata": {},
   "source": [
    "## 7. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4aa606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred):\n",
    "    \"\"\"SMAPE metric\"\"\"\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
    "    diff = np.abs(y_true - y_pred)\n",
    "    return np.mean(diff / denominator) * 100\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ TRAINING MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ==================== LIGHTGBM ====================\n",
    "print(\"\\n1Ô∏è‚É£ Training LightGBM...\")\n",
    "\n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'learning_rate': 0.03,\n",
    "    'num_leaves': 63,\n",
    "    'max_depth': 8,\n",
    "    'min_child_samples': 20,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.3,\n",
    "    'reg_lambda': 0.3,\n",
    "    'random_state': 42,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train_log)\n",
    "val_data = lgb.Dataset(X_val, label=y_val_log, reference=train_data)\n",
    "\n",
    "lgb_model = lgb.train(\n",
    "    lgb_params,\n",
    "    train_data,\n",
    "    num_boost_round=2000,\n",
    "    valid_sets=[val_data],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=150), lgb.log_evaluation(0)]\n",
    ")\n",
    "\n",
    "y_pred_lgb_log = lgb_model.predict(X_val)\n",
    "y_pred_lgb = np.expm1(y_pred_lgb_log)\n",
    "smape_lgb = smape(y_val, y_pred_lgb)\n",
    "print(f\"   LightGBM SMAPE: {smape_lgb:.2f}%\")\n",
    "\n",
    "# ==================== XGBOOST ====================\n",
    "print(\"\\n2Ô∏è‚É£ Training XGBoost...\")\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'learning_rate': 0.03,\n",
    "    'max_depth': 8,\n",
    "    'min_child_weight': 3,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'gamma': 0.1,\n",
    "    'reg_alpha': 0.3,\n",
    "    'reg_lambda': 0.3,\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train_log)\n",
    "dval = xgb.DMatrix(X_val, label=y_val_log)\n",
    "\n",
    "xgb_model = xgb.train(\n",
    "    xgb_params,\n",
    "    dtrain,\n",
    "    num_boost_round=2000,\n",
    "    evals=[(dval, 'val')],\n",
    "    early_stopping_rounds=150,\n",
    "    verbose_eval=0\n",
    ")\n",
    "\n",
    "y_pred_xgb_log = xgb_model.predict(dval)\n",
    "y_pred_xgb = np.expm1(y_pred_xgb_log)\n",
    "smape_xgb = smape(y_val, y_pred_xgb)\n",
    "print(f\"   XGBoost SMAPE: {smape_xgb:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä INDIVIDUAL MODEL RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"LightGBM: {smape_lgb:.2f}%\")\n",
    "print(f\"XGBoost:  {smape_xgb:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabb7dce",
   "metadata": {},
   "source": [
    "## 8. Ensemble Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea57a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîß OPTIMIZING ENSEMBLE WEIGHTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def smape_loss(weights):\n",
    "    ensemble = weights[0] * y_pred_lgb + weights[1] * y_pred_xgb\n",
    "    return smape(y_val, ensemble)\n",
    "\n",
    "constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "bounds = [(0, 1)] * 2\n",
    "initial_weights = [0.5, 0.5]\n",
    "\n",
    "result = minimize(smape_loss, x0=initial_weights, bounds=bounds, constraints=constraints, method='SLSQP')\n",
    "optimal_weights = result.x\n",
    "\n",
    "print(f\"\\n‚úÖ Optimal weights:\")\n",
    "print(f\"   LightGBM: {optimal_weights[0]:.3f}\")\n",
    "print(f\"   XGBoost:  {optimal_weights[1]:.3f}\")\n",
    "\n",
    "y_pred_ensemble = optimal_weights[0] * y_pred_lgb + optimal_weights[1] * y_pred_xgb\n",
    "smape_ensemble = smape(y_val, y_pred_ensemble)\n",
    "\n",
    "print(f\"\\nüèÜ FINAL ENSEMBLE SMAPE: {smape_ensemble:.2f}%\")\n",
    "\n",
    "if smape_ensemble < 45:\n",
    "    print(\"   üéâ EXCELLENT! Should be competitive!\")\n",
    "elif smape_ensemble < 48:\n",
    "    print(\"   ‚úÖ GOOD! Better than before!\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Need further improvement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de23789",
   "metadata": {},
   "source": [
    "## 9. Generate Final Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d316ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ GENERATING FINAL PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Prepare test data\n",
    "X_num_test = test[num_feature_cols].fillna(0)\n",
    "X_num_test_scaled = scaler.transform(X_num_test)\n",
    "\n",
    "if use_images and test_img_features is not None:\n",
    "    X_test_combined = np.hstack([X_num_test_scaled, test_img_features.values])\n",
    "else:\n",
    "    X_test_combined = X_num_test_scaled\n",
    "\n",
    "# Generate predictions\n",
    "print(\"\\nGenerating predictions...\")\n",
    "\n",
    "y_test_lgb_log = lgb_model.predict(X_test_combined)\n",
    "y_test_lgb = np.expm1(y_test_lgb_log)\n",
    "\n",
    "dtest = xgb.DMatrix(X_test_combined)\n",
    "y_test_xgb_log = xgb_model.predict(dtest)\n",
    "y_test_xgb = np.expm1(y_test_xgb_log)\n",
    "\n",
    "# Ensemble\n",
    "y_test_ensemble = optimal_weights[0] * y_test_lgb + optimal_weights[1] * y_test_xgb\n",
    "y_test_ensemble = np.clip(y_test_ensemble, 0.01, None)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'sample_id': test['sample_id'],\n",
    "    'price': y_test_ensemble\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_brand_image.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ SUBMISSION CREATED!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìù Filename: submission_brand_image.csv\")\n",
    "print(f\"üìä Statistics:\")\n",
    "print(f\"   Samples:  {len(submission)}\")\n",
    "print(f\"   Min:      ${submission['price'].min():.2f}\")\n",
    "print(f\"   Max:      ${submission['price'].max():.2f}\")\n",
    "print(f\"   Mean:     ${submission['price'].mean():.2f}\")\n",
    "print(f\"   Median:   ${submission['price'].median():.2f}\")\n",
    "\n",
    "print(f\"\\nüéØ Performance Expectations:\")\n",
    "print(f\"   Validation SMAPE: {smape_ensemble:.2f}%\")\n",
    "print(f\"   Expected Test:    {smape_ensemble:.1f}-{smape_ensemble+2:.1f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ Key improvements:\")\n",
    "print(\"   ‚Ä¢ Brand-focused features (critical for pricing)\")\n",
    "print(\"   ‚Ä¢ Out-of-fold encoding (no leakage)\")\n",
    "if use_images:\n",
    "    print(\"   ‚Ä¢ miniCLIP image features (512-dim, less noise)\")\n",
    "print(\"   ‚Ä¢ Simple 2-model ensemble (LightGBM + XGBoost)\")\n",
    "print(\"   ‚Ä¢ No complex embeddings (focus on price signals)\")\n",
    "\n",
    "print(\"\\nüöÄ Ready to submit!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
