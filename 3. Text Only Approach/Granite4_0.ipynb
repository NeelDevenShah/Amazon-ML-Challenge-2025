{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ogWq-YsXeHR"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIqkP1byXeHW"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--E1tC7pXeHX"
      },
      "source": [
        "\n",
        "Unsloth's [Docker image](https://hub.docker.com/r/unsloth/unsloth) is here! Start training with no setup & environment issues. [Read our Guide](https://docs.unsloth.ai/new/how-to-train-llms-with-unsloth-and-docker).\n",
        "\n",
        "[gpt-oss RL](https://docs.unsloth.ai/new/gpt-oss-reinforcement-learning) is now supported with the fastest inference & lowest VRAM. Try our [new notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-GRPO.ipynb) which creates kernels!\n",
        "\n",
        "Introducing [Vision](https://docs.unsloth.ai/new/vision-reinforcement-learning-vlm-rl) and [Standby](https://docs.unsloth.ai/basics/memory-efficient-rl) for RL! Train Qwen, Gemma etc. VLMs with GSPO - even faster with less VRAM.\n",
        "\n",
        "Unsloth now supports Text-to-Speech (TTS) models. Read our [guide here](https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning).\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO1fE88OXeHY"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_71Dv9bXeHY"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
        "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
        "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "!pip install transformers==4.55.4\n",
        "!pip install --no-deps trl==0.22.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0GIyDEnG7GS"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# These are mamba kernels and we must have these for faster training\n",
        "!pip install --no-build-isolation mamba_ssm==2.2.5\n",
        "!pip install --no-build-isolation causal_conv1d==1.5.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGMWlrRdzwgf"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "7c9936cd3bbf430bbcf69f7a2648e716",
            "ce4aa788f8ca48ab81305e428e174374",
            "ecb7209ff3bb45f89a59e84972e5d978",
            "dd17c05cc47949ec85d5e43903ab7ae0",
            "191b6a8100e84d9a939e11ee81de4a83",
            "fea9c1a564d1482fbb2d4c9db0249bfa",
            "cfd5bf250f334e19b8cc1bc217bf33f7",
            "ff5cb7e5b5e24fdc9ca6ecaa43e1ae10",
            "b26644a0095d43bb975c5443d51233e4",
            "c9da52df017244ab8d0767fc6b091996",
            "ccc811b8517e4b568a91ae9d24131512"
          ]
        },
        "id": "-Xbb0cuLzwgf",
        "outputId": "af47dcf2-8528-4d7a-eb28-149d108b467f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.9.11: Fast Granitemoehybrid patching. Transformers: 4.55.4.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The fast path for GraniteMoeHybrid will be used when running the model on a GPU\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c9936cd3bbf430bbcf69f7a2648e716",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "fourbit_models = [\n",
        "    \"unsloth/granite-4.0-micro\",\n",
        "    \"unsloth/granite-4.0-h-micro\",\n",
        "    \"unsloth/granite-4.0-h-tiny\",\n",
        "    \"unsloth/granite-4.0-h-small\",\n",
        "\n",
        "    # Base pretrained Granite 4 models\n",
        "    \"unsloth/granite-4.0-micro-base\",\n",
        "    \"unsloth/granite-4.0-h-micro-base\",\n",
        "    \"unsloth/granite-4.0-h-tiny-base\",\n",
        "    \"unsloth/granite-4.0-h-small-base\",\n",
        "\n",
        "    # 4bit dynamic quants for superior accuracy and low memory use\n",
        "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/Phi-4\",\n",
        "    \"unsloth/Llama-3.1-8B\",\n",
        "    \"unsloth/Llama-3.2-3B\",\n",
        "    \"unsloth/orpheus-3b-0.1-ft-unsloth-bnb-4bit\" # [NEW] We support TTS models!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/granite-4.0-h-tiny-base\",\n",
        "    max_seq_length = 2048,   # Choose any for long context!\n",
        "    load_in_4bit = False,    # 4 bit quantization to reduce memory\n",
        "    load_in_8bit = False,    # [NEW!] A bit more accurate, uses 2x memory\n",
        "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update a small amount of parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "30ff7bd4-88cf-447d-b33d-59821d993d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Making `model.base_model.model.model` require gradients\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 32, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "                      \"shared_mlp.input_linear\", \"shared_mlp.output_linear\"],\n",
        "    lora_alpha = 32,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "#### üìÑ Using Google Sheets as Training Data\n",
        "Our goal is to create a customer support bot that proactively helps and solves issues.\n",
        "\n",
        "We‚Äôre storing examples in a Google Sheet with two columns:\n",
        "\n",
        "- **Snippet**: A short customer support interaction\n",
        "- **Recommendation**: A suggestion for how the agent should respond\n",
        "\n",
        "This keeps things simple and collaborative. Anyone can edit the sheet, no database setup required.  \n",
        "<br>\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "#### üîç Why This Format?\n",
        "\n",
        "This setup works well for tasks like:\n",
        "\n",
        "- `Input snippet ‚Üí Suggested reply`\n",
        "- `Prompt ‚Üí Rewrite`\n",
        "- `Bug report ‚Üí Diagnosis`\n",
        "- `Text ‚Üí Label or Category`\n",
        "\n",
        "Just collect examples in a spreadsheet, and you‚Äôve got usable training data.  \n",
        "<br>\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "#### ‚úÖ What You'll Learn\n",
        "\n",
        "We‚Äôll show how to:\n",
        "\n",
        "1. Load the Google Sheet into your notebook\n",
        "2. Format it into a dataset\n",
        "3. Use it to train or prompt an LLM\n",
        "\n",
        "\n",
        "The chat template for granite-4 look like this:\n",
        "```\n",
        "<|start_of_role|>system<|end_of_role|>Knowledge Cutoff Date: April 2024.\n",
        "Today's Date: June 24, 2025.\n",
        "You are Granite, developed by IBM. You are a helpful AI assistant.<|end_of_text|>\n",
        "\n",
        "<|start_of_role|>user<|end_of_role|>How do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?<|end_of_text|>\n",
        "\n",
        "<|start_of_role|>assistant<|end_of_role|>Astronomers make use of the unique spectral fingerprints of elements found in stars...<|end_of_text|>\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "7216e702e8ec4305a386b5447e468ecb",
            "fc8739e60d6844669a51a137c48a6218",
            "b346d68403ee499b9070ee974c5e05e5",
            "86082ed4f0824faa9b996047a28a4525",
            "48169ddbaf7649b88594e8d110854b35",
            "3d728fdd8eb24ed09a0ea06e58db01e3",
            "cab523c6b34d48af9d6f52c62ff64a64",
            "67cd1b3132444520a8794adfcc44c223",
            "0759e398938a4095ba9af12b9ccad04d",
            "9481dda959ee4436b42e8c6c923231d0",
            "8bf2866db80d4a5797b6f9edceea1a67",
            "9de6933d0e0d432cb8121c63d287053a",
            "c7777936dc2e41568bc2649bb02a763b",
            "551ee4eac5bc455b93b1d0bab7a229c4",
            "fbdf439f327f4ceb8c24360ff66abe6b",
            "38731ca21c514685bd6db34cca54b56f",
            "a17bf82d1ad9468dbdbad8038f4715cc",
            "2d2bf2089a4343fcbce758086e216f34",
            "d7faeab15e0346e696d35d130a070d47",
            "e0d6a5c340d749479c1d94adf17bb981",
            "b9f552bcbccf42dca02a5ccdfd5eb871",
            "2b6eb0208d664e79be39927c02788eed"
          ]
        },
        "id": "Mkq4RvEq7FQr",
        "outputId": "84a49162-852a-4afb-f349-394ba7337a7b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7216e702e8ec4305a386b5447e468ecb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9de6933d0e0d432cb8121c63d287053a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from datasets import Dataset\n",
        "\n",
        "# Enhanced text cleaning function - extracts key features AND keeps full text\n",
        "def clean_text_enhanced(text):\n",
        "    if pd.isnull(text):\n",
        "        return \"\"\n",
        "    \n",
        "    # Convert to string and clean basic issues\n",
        "    text = str(text).strip()\n",
        "    \n",
        "    # Extract ALL structured information (not just top 3)\n",
        "    item_name = re.search(r\"Item Name:\\s*(.*?)(?=\\n|$)\", text, re.IGNORECASE)\n",
        "    brand = re.search(r\"Brand:\\s*(.*?)(?=\\n|$)\", text, re.IGNORECASE)\n",
        "    color = re.search(r\"Color:\\s*(.*?)(?=\\n|$)\", text, re.IGNORECASE)\n",
        "    size = re.search(r\"Size:\\s*(.*?)(?=\\n|$)\", text, re.IGNORECASE)\n",
        "    material = re.search(r\"Material:\\s*(.*?)(?=\\n|$)\", text, re.IGNORECASE)\n",
        "    model = re.search(r\"Model:\\s*(.*?)(?=\\n|$)\", text, re.IGNORECASE)\n",
        "    \n",
        "    # Extract bullet points (all of them)\n",
        "    bp1 = re.search(r\"Bullet Point\\s*1:\\s*(.*?)(?=\\n|$)\", text, re.IGNORECASE)\n",
        "    bp2 = re.search(r\"Bullet Point\\s*2:\\s*(.*?)(?=\\n|$)\", text, re.IGNORECASE)\n",
        "    bp3 = re.search(r\"Bullet Point\\s*3:\\s*(.*?)(?=\\n|$)\", text, re.IGNORECASE)\n",
        "    bp4 = re.search(r\"Bullet Point\\s*4:\\s*(.*?)(?=\\n|$)\", text, re.IGNORECASE)\n",
        "    bp5 = re.search(r\"Bullet Point\\s*5:\\s*(.*?)(?=\\n|$)\", text, re.IGNORECASE)\n",
        "    \n",
        "    # Extract value and unit\n",
        "    value = re.search(r\"Value:\\s*([\\d.,]+)\", text, re.IGNORECASE)\n",
        "    unit = re.search(r\"Unit:\\s*([A-Za-z]+)\", text, re.IGNORECASE)\n",
        "    \n",
        "    # Extract description if present\n",
        "    description = re.search(r\"Description:\\s*(.*?)(?=\\n|$)\", text, re.IGNORECASE)\n",
        "    \n",
        "    # Build structured output with KEY features first, then append everything else\n",
        "    structured_parts = []\n",
        "    \n",
        "    # Top priority features (Item Name, Value, Unit)\n",
        "    if item_name:\n",
        "        structured_parts.append(f\"Item: {item_name.group(1).strip()}\")\n",
        "    if value and unit:\n",
        "        structured_parts.append(f\"Quantity: {value.group(1).strip()} {unit.group(1).strip()}\")\n",
        "    elif value:\n",
        "        structured_parts.append(f\"Value: {value.group(1).strip()}\")\n",
        "    \n",
        "    # Additional important features\n",
        "    if brand:\n",
        "        structured_parts.append(f\"Brand: {brand.group(1).strip()}\")\n",
        "    if color:\n",
        "        structured_parts.append(f\"Color: {color.group(1).strip()}\")\n",
        "    if size:\n",
        "        structured_parts.append(f\"Size: {size.group(1).strip()}\")\n",
        "    if material:\n",
        "        structured_parts.append(f\"Material: {material.group(1).strip()}\")\n",
        "    if model:\n",
        "        structured_parts.append(f\"Model: {model.group(1).strip()}\")\n",
        "    \n",
        "    # All bullet points\n",
        "    if bp1:\n",
        "        structured_parts.append(f\"Feature 1: {bp1.group(1).strip()}\")\n",
        "    if bp2:\n",
        "        structured_parts.append(f\"Feature 2: {bp2.group(1).strip()}\")\n",
        "    if bp3:\n",
        "        structured_parts.append(f\"Feature 3: {bp3.group(1).strip()}\")\n",
        "    if bp4:\n",
        "        structured_parts.append(f\"Feature 4: {bp4.group(1).strip()}\")\n",
        "    if bp5:\n",
        "        structured_parts.append(f\"Feature 5: {bp5.group(1).strip()}\")\n",
        "    \n",
        "    if description:\n",
        "        structured_parts.append(f\"Description: {description.group(1).strip()}\")\n",
        "    \n",
        "    # Join structured parts\n",
        "    cleaned_text = \". \".join(structured_parts)\n",
        "    \n",
        "    # IMPORTANT: Append the FULL original text (cleaned) so nothing is lost\n",
        "    # This ensures ALL information is available to the model\n",
        "    full_text_cleaned = text.lower()\n",
        "    full_text_cleaned = re.sub(r'[^\\w\\s.,:\\-]', ' ', full_text_cleaned)\n",
        "    full_text_cleaned = re.sub(r'\\s+', ' ', full_text_cleaned)\n",
        "    full_text_cleaned = full_text_cleaned.strip()\n",
        "    \n",
        "    # Combine: structured features first, then full text for additional context\n",
        "    if cleaned_text and full_text_cleaned:\n",
        "        final_text = f\"{cleaned_text}. Full Details: {full_text_cleaned}\"\n",
        "    elif cleaned_text:\n",
        "        final_text = cleaned_text\n",
        "    else:\n",
        "        final_text = full_text_cleaned\n",
        "    \n",
        "    return final_text\n",
        "\n",
        "print(\"Loading training data from dataset/train.csv...\")\n",
        "train_df = pd.read_csv('dataset/train.csv', encoding='latin1')\n",
        "\n",
        "print(f\"Original data shape: {train_df.shape}\")\n",
        "print(f\"Columns: {train_df.columns.tolist()}\")\n",
        "\n",
        "# Apply text cleaning\n",
        "print(\"\\nApplying enhanced text cleaning...\")\n",
        "train_df['catalog_content'] = train_df['catalog_content'].apply(clean_text_enhanced)\n",
        "\n",
        "# Filter out empty or very short text\n",
        "train_df['text_length'] = train_df['catalog_content'].str.len()\n",
        "train_df = train_df[train_df['text_length'] > 10].copy()\n",
        "\n",
        "print(f\"Data shape after cleaning: {train_df.shape}\")\n",
        "print(f\"\\nPrice statistics:\")\n",
        "print(train_df['price'].describe())\n",
        "\n",
        "# Convert to HuggingFace Dataset format\n",
        "dataset = Dataset.from_pandas(train_df[['catalog_content', 'price']])\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset loaded: {len(dataset)} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9CBpiISFa6C"
      },
      "source": [
        "We've just loaded the Google Sheet as a csv style Dataset, but we still need to format it into conversational style like below and then apply the chat template.\n",
        "\n",
        "```\n",
        "{\"role\": \"system\", \"content\": \"You are an assistant\"}\n",
        "{\"role\": \"user\", \"content\": \"What is 2+2?\"}\n",
        "{\"role\": \"assistant\", \"content\": \"It's 4.\"}\n",
        "```\n",
        "\n",
        "We'll use a helper function `formatting_prompts_func` to do both!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "feffcb8924db4212b95fba1dac496a8e",
            "9d1f73c83e6b4856b2c5d4039eb2a75c",
            "ff1f74f1b8434a9388adfbb77a0bec8f",
            "0acfdad4a12a433f9084930d2903a4c7",
            "0e91915212da4b699568b2931b2563c1",
            "3749d01cb5834e479232b55150dc024e",
            "0fc8224771044c749e66770d939ca1cd",
            "087930aaf9674d23adb19fb41ca3d78b",
            "2596a30288044233923b390c0703b5de",
            "bb63137aa20041759b8f2db481107170",
            "2f4909b235b648c0942daaa1ae2d84f3"
          ]
        },
        "id": "reoBXmAn7HlN",
        "outputId": "8808050a-294d-49a0-9bb4-3951ee65e72c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "feffcb8924db4212b95fba1dac496a8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/504 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def formatting_prompts_func(examples):\n",
        "    catalog_texts = examples['catalog_content']\n",
        "    prices = examples['price']\n",
        "    \n",
        "    messages = [\n",
        "        [{\"role\": \"user\", \"content\": f\"Predict the price for this product: {catalog_text}\"},\n",
        "         {\"role\": \"assistant\", \"content\": f\"The predicted price is ${price:.2f}\"}] \n",
        "        for catalog_text, price in zip(catalog_texts, prices)\n",
        "    ]\n",
        "    \n",
        "    # This will now work correctly\n",
        "    texts = [tokenizer.apply_chat_template(message, tokenize=False, add_generation_prompt=False) \n",
        "             for message in messages]\n",
        "    \n",
        "    return {\"text\": texts}\n",
        "\n",
        "print(\"Formatting dataset with chat template...\")\n",
        "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
        "print(f\"‚úÖ Dataset formatted: {len(dataset)} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i5Sx9In7vHi"
      },
      "source": [
        "We now look at the raw input data before formatting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "dzE1OEXi7s3P",
        "outputId": "c646ed26-f14d-4d78-fe03-3a8bf698e085"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'User: I\\'m getting an error when trying to log in. \\nAgent: What error message are you seeing? \\nUser: It says \"Invalid credentials\" even though I\\'m sure my password is correct. \\nAgent: Have you tried clearing your browser cache? \\nUser: Yes, I cleared it already. \\nAgent: Let me check your account status. \\nUser: I\\'ve been using this account for months without issues. \\nAgent: I found no issues with your account. \\nUser: Maybe there\\'s a problem with the login server? \\nAgent: Let\\'s try resetting your password. \\nUser: I just did that, and it\\'s not working either. \\nAgent: I\\'ll need to escalate this to our engineering team. \\nUser: Okay, what should I do in the meantime? \\nAgent: Try using a different browser or device. \\nUser: I\\'ll try Chrome on my laptop. \\nAgent: Let me know if that resolves the issue.'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show raw catalog content before formatting\n",
        "print(\"Sample catalog content:\")\n",
        "print(dataset[5][\"catalog_content\"][:500])  # Show first 500 chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "LA-aC7w-x72-",
        "outputId": "69269256-3370-461f-f722-769446775125"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#### Analysis\\nThe user is experiencing persistent login issues (\"Invalid credentials\", password reset failure) despite clearing cache and confirming correct credentials. No account anomalies were detected by the agent. The root cause remains unresolved and potentially related to server-side authentication or user-specific credential handling.\\n\\n#### Recommendation\\n- Step 1: Confirm if using Chrome on the laptop resolved the login issue. (User action)\\n- Step 2: If Step 1 was successful, no further immediate action needed. If not, proceed to escalate based on user feedback.\\n- *Next best action for the agent*: Report back to the user whether using Chrome on their laptop confirmed or failed to resolve the issue.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show the corresponding price\n",
        "print(\"Sample price:\")\n",
        "print(f\"${dataset[5]['price']:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q76PqXv9yKa0"
      },
      "source": [
        "And we see how the chat template transformed these conversations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "du1MB2NqyGW4",
        "outputId": "3dc9fe2b-9fdc-4dcd-f0db-ceb76c2191a3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|start_of_role|>user<|end_of_role|>User: I\\'m getting an error when trying to log in. \\nAgent: What error message are you seeing? \\nUser: It says \"Invalid credentials\" even though I\\'m sure my password is correct. \\nAgent: Have you tried clearing your browser cache? \\nUser: Yes, I cleared it already. \\nAgent: Let me check your account status. \\nUser: I\\'ve been using this account for months without issues. \\nAgent: I found no issues with your account. \\nUser: Maybe there\\'s a problem with the login server? \\nAgent: Let\\'s try resetting your password. \\nUser: I just did that, and it\\'s not working either. \\nAgent: I\\'ll need to escalate this to our engineering team. \\nUser: Okay, what should I do in the meantime? \\nAgent: Try using a different browser or device. \\nUser: I\\'ll try Chrome on my laptop. \\nAgent: Let me know if that resolves the issue.<|end_of_text|>\\n<|start_of_role|>assistant<|end_of_role|>#### Analysis\\nThe user is experiencing persistent login issues (\"Invalid credentials\", password reset failure) despite clearing cache and confirming correct credentials. No account anomalies were detected by the agent. The root cause remains unresolved and potentially related to server-side authentication or user-specific credential handling.\\n\\n#### Recommendation\\n- Step 1: Confirm if using Chrome on the laptop resolved the login issue. (User action)\\n- Step 2: If Step 1 was successful, no further immediate action needed. If not, proceed to escalate based on user feedback.\\n- *Next best action for the agent*: Report back to the user whether using Chrome on their laptop confirmed or failed to resolve the issue.<|end_of_text|>\\n'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[5][\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's train our model. We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "c0ee71d150f648ceb740af021342dc88",
            "cc5da287b7d247388674d53317ed8864",
            "a58e7b92da104470959e2e2cb8439c3b",
            "66cc062d92924dbc9d91896352347e34",
            "9c854d05981044279ea79792ce50c64f",
            "96334dca3a004ddeae99af2304c25b30",
            "8daa961157694497a8ca1bb1c4bcff0b",
            "f129ebb055724b73b4017f0396389cca",
            "18f56a4308634623afb95428a54edd0f",
            "4b73f84a06754e5d8fc832e20a693695",
            "fa69243ce6de4eafbcdb7c34a23ee5b5"
          ]
        },
        "id": "95_Nn-89DhsL",
        "outputId": "bfc58eeb-67cf-4e35-a8ab-165ddef13d9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: We found double BOS tokens - we shall remove one automatically.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0ee71d150f648ceb740af021342dc88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/504 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from trl import SFTTrainer, SFTConfig\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    eval_dataset = None, # Can set up evaluation!\n",
        "    args = SFTConfig(\n",
        "        dataset_text_field = \"text\",\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4, # Use GA to mimic batch size!\n",
        "        warmup_steps = 5,\n",
        "        num_train_epochs = 2, # Set this for 1 full training run.\n",
        "        # max_steps = 60,\n",
        "        learning_rate = 2e-4, # Reduce to 2e-5 for long training runs\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        report_to = \"none\", # Use this for WandB etc\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_sGp5XlG6dq"
      },
      "source": [
        "We also use Unsloth's `train_on_completions` method to only train on the assistant outputs and ignore the loss on the user's inputs. This helps increase accuracy of finetunes!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "909fb7562ae64dca9c888e00b2f7f881",
            "62f3983a614f4566ad043a3de97a7114",
            "9de4b3e3ec324af8be09fcc99c35a7f9",
            "c17629fa71064480a2283c94b3fa0951",
            "11bbc91e0e9d4164978a147fc4b8ce68",
            "107ed420bf174d149ff7b64dd1d15c43",
            "e709b2fe6ad541579acaa430c862fb3f",
            "b02287b961634d719ee3e4fade474c47",
            "a522c6b18f9744259851fe33a88705bf",
            "74de35f7e7824f39abb1a7dd37ab8669",
            "91f0a47939ff4891808591fa9df9ce6c"
          ]
        },
        "id": "juQiExuBG5Bt",
        "outputId": "303bac9a-823b-47fa-8241-3a3bebd7a602"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "909fb7562ae64dca9c888e00b2f7f881",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/504 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from unsloth.chat_templates import train_on_responses_only\n",
        "# trainer = train_on_responses_only(\n",
        "#     trainer,\n",
        "#     instruction_part = \"<|start_of_role|>user<|end_of_role|>\",\n",
        "#     response_part = \"<|start_of_role|>assistant<|end_of_role|>\",\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv1NBUozV78l"
      },
      "source": [
        "Let's verify masking the instruction part is done! Let's print the 100th row again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "LtsMVtlkUhja",
        "outputId": "6847332a-197d-4060-9d97-190dd284e948"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|start_of_role|>user<|end_of_role|>User: My account is locked. I tried to log in but got an error message saying \"Too many failed attempts\".\\n\\nAgent: Can you please try logging in again and enter the security code sent to your email? That should unlock your account temporarily.\\n\\nUser: I did that already. I received the code and entered it, but my account is still locked.\\n\\nAgent: I see. Have you tried resetting your password via the \\'Forgot Password\\' link?\\n\\nUser: Yes, I clicked on that. It sent me an email with a reset link, but when I tried to reset my password, I got an error message saying \"Invalid request\".\\n\\nAgent: Okay, I can\\'t access your account to check directly. Could you please provide me with your account ID or email address associated with the account?\\n\\nUser: My email is user@example.com. Account ID is 123456789.\\n\\nAgent: Thank you. I\\'m looking into this. It seems there might be an issue with the account lockout mechanism or the password reset process. I\\'ll need to contact our security team to manually unlock your account and investigate further. I\\'ll keep you updated on the progress.<|end_of_text|>\\n<|start_of_role|>assistant<|end_of_role|>#### Analysis\\nThe user is experiencing account lockout due to multiple failed login attempts, and standard troubleshooting steps like password reset and security code entry are failing, indicating a potential issue with the account lockout mechanism or password recovery system.\\n\\n#### Recommendation\\n- Step 1: Attempt to reset the password using the \\'Forgot Password\\' link and provide the error details received.\\n- Step 2: Contact support with the account ID/email and request manual account unlock and investigation.\\n- *Next best action for the agent*: Instruct the user to contact support immediately, providing their account details for manual intervention and further investigation.<|end_of_text|>\\n'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verify the full formatted text (input_ids)\n",
        "if len(trainer.train_dataset) > 100:\n",
        "    print(\"Full formatted example:\")\n",
        "    print(tokenizer.decode(trainer.train_dataset[100][\"input_ids\"]))\n",
        "else:\n",
        "    print(f\"Dataset only has {len(trainer.train_dataset)} samples. Showing first sample:\")\n",
        "    print(tokenizer.decode(trainer.train_dataset[0][\"input_ids\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Kyjy__m9KY3"
      },
      "source": [
        "Now let's print the masked out example - you should see only the answer is present:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "_rD6fl8EUxnG",
        "outputId": "28ea6c53-5376-4b4d-8d6b-9303fa943d5f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"                                                                                                                                                                                                                                                 #### Analysis\\nThe user is experiencing account lockout due to multiple failed login attempts, and standard troubleshooting steps like password reset and security code entry are failing, indicating a potential issue with the account lockout mechanism or password recovery system.\\n\\n#### Recommendation\\n- Step 1: Attempt to reset the password using the 'Forgot Password' link and provide the error details received.\\n- Step 2: Contact support with the account ID/email and request manual account unlock and investigation.\\n- *Next best action for the agent*: Instruct the user to contact support immediately, providing their account details for manual intervention and further investigation.<|end_of_text|>\\n\""
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Now let's print the masked out example - you should see only the assistant response\n",
        "if len(trainer.train_dataset) > 100:\n",
        "    sample_idx = 100\n",
        "else:\n",
        "    sample_idx = 0\n",
        "\n",
        "if \"labels\" in trainer.train_dataset[sample_idx]:\n",
        "    masked_labels = [tokenizer.pad_token_id if x == -100 else x for x in trainer.train_dataset[sample_idx][\"labels\"]]\n",
        "    decoded = tokenizer.decode(masked_labels)\n",
        "    if tokenizer.pad_token:\n",
        "        decoded = decoded.replace(tokenizer.pad_token, \" \")\n",
        "    print(\"Masked output (only assistant response should be visible):\")\n",
        "    print(decoded)\n",
        "else:\n",
        "    print(\"Labels field not found. The masking will be applied during training.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "5621be39-f821-45a9-8af0-c8a927f60d21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "6.059 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNP1Uidk9mrz"
      },
      "source": [
        "Let's train the model! To resume a training run, set `trainer.train(resume_from_checkpoint = True)`\n",
        "\n",
        "```\n",
        "Notice you might have to wait ~10 minutes for the Mamba kernels to compile! Please be patient!\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "ae607ec1-76b0-4c4f-a117-b7126886e58a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 504 | Num Epochs = 1 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 1,703,936 of 3,193,100,032 (0.05% trained)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 06:38, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.893200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.193700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.385300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.949300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.909700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.066900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.923100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.053300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.503300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.325700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.352200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.807200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.629000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.233600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.699000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.547100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.678400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.548900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.197600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.353900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.487300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.335600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.281100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.560200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.750500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.331500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.068000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.248100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.445800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.722400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.849400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.297800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.238500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.273300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.082300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.168300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.298700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.045200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.244500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.201900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.276200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.212700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.011200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.159400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.310300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.207200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.025800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.230800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.118100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.113900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.386500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.237000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.429900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.125200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.882900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.148100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.617100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.499600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.432000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.132300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCqnaKmlO1U9",
        "outputId": "341ad3e5-ef7c-406b-d6fc-641cf5729ca4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "954.0727 seconds used for training.\n",
            "15.9 minutes used for training.\n",
            "Peak reserved memory = 10.42 GB.\n",
            "Peak reserved memory for training = 4.361 GB.\n",
            "Peak reserved memory % of max memory = 70.687 %.\n",
            "Peak reserved memory for training % of max memory = 29.584 %.\n"
          ]
        }
      ],
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model via Unsloth native inference! We'll use some example snippets not contained in our training data to get a sense of what was learned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Fast Inference with vLLM\n",
        "\n",
        "‚ö° **IMPORTANT**: Instead of slow one-by-one predictions (30+ hours), we'll use vLLM for fast batched inference!\n",
        "\n",
        "**Steps:**\n",
        "1. ‚úÖ Train the model (done above)\n",
        "2. ‚úÖ Save in vLLM-compatible format (merged 16-bit)\n",
        "3. üöÄ Use the vLLM script below for fast batched predictions\n",
        "\n",
        "With vLLM on A100, predictions should take **minutes instead of hours**!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a fast vLLM inference script\n",
        "vllm_script = '''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from vllm import LLM, SamplingParams\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Same text cleaning function\n",
        "def clean_text_enhanced(text):\n",
        "    if pd.isnull(text):\n",
        "        return \"\"\n",
        "    \n",
        "    text = str(text).strip()\n",
        "    \n",
        "    # Extract structured information\n",
        "    item_name = re.search(r\"Item Name:\\\\s*(.*?)(?=\\\\n|$)\", text, re.IGNORECASE)\n",
        "    brand = re.search(r\"Brand:\\\\s*(.*?)(?=\\\\n|$)\", text, re.IGNORECASE)\n",
        "    color = re.search(r\"Color:\\\\s*(.*?)(?=\\\\n|$)\", text, re.IGNORECASE)\n",
        "    size = re.search(r\"Size:\\\\s*(.*?)(?=\\\\n|$)\", text, re.IGNORECASE)\n",
        "    material = re.search(r\"Material:\\\\s*(.*?)(?=\\\\n|$)\", text, re.IGNORECASE)\n",
        "    model = re.search(r\"Model:\\\\s*(.*?)(?=\\\\n|$)\", text, re.IGNORECASE)\n",
        "    \n",
        "    bp1 = re.search(r\"Bullet Point\\\\s*1:\\\\s*(.*?)(?=\\\\n|$)\", text, re.IGNORECASE)\n",
        "    bp2 = re.search(r\"Bullet Point\\\\s*2:\\\\s*(.*?)(?=\\\\n|$)\", text, re.IGNORECASE)\n",
        "    bp3 = re.search(r\"Bullet Point\\\\s*3:\\\\s*(.*?)(?=\\\\n|$)\", text, re.IGNORECASE)\n",
        "    bp4 = re.search(r\"Bullet Point\\\\s*4:\\\\s*(.*?)(?=\\\\n|$)\", text, re.IGNORECASE)\n",
        "    bp5 = re.search(r\"Bullet Point\\\\s*5:\\\\s*(.*?)(?=\\\\n|$)\", text, re.IGNORECASE)\n",
        "    \n",
        "    value = re.search(r\"Value:\\\\s*([\\\\d.,]+)\", text, re.IGNORECASE)\n",
        "    unit = re.search(r\"Unit:\\\\s*([A-Za-z]+)\", text, re.IGNORECASE)\n",
        "    description = re.search(r\"Description:\\\\s*(.*?)(?=\\\\n|$)\", text, re.IGNORECASE)\n",
        "    \n",
        "    structured_parts = []\n",
        "    \n",
        "    if item_name:\n",
        "        structured_parts.append(f\"Item: {item_name.group(1).strip()}\")\n",
        "    if value and unit:\n",
        "        structured_parts.append(f\"Quantity: {value.group(1).strip()} {unit.group(1).strip()}\")\n",
        "    elif value:\n",
        "        structured_parts.append(f\"Value: {value.group(1).strip()}\")\n",
        "    \n",
        "    if brand:\n",
        "        structured_parts.append(f\"Brand: {brand.group(1).strip()}\")\n",
        "    if color:\n",
        "        structured_parts.append(f\"Color: {color.group(1).strip()}\")\n",
        "    if size:\n",
        "        structured_parts.append(f\"Size: {size.group(1).strip()}\")\n",
        "    if material:\n",
        "        structured_parts.append(f\"Material: {material.group(1).strip()}\")\n",
        "    if model:\n",
        "        structured_parts.append(f\"Model: {model.group(1).strip()}\")\n",
        "    \n",
        "    if bp1:\n",
        "        structured_parts.append(f\"Feature 1: {bp1.group(1).strip()}\")\n",
        "    if bp2:\n",
        "        structured_parts.append(f\"Feature 2: {bp2.group(1).strip()}\")\n",
        "    if bp3:\n",
        "        structured_parts.append(f\"Feature 3: {bp3.group(1).strip()}\")\n",
        "    if bp4:\n",
        "        structured_parts.append(f\"Feature 4: {bp4.group(1).strip()}\")\n",
        "    if bp5:\n",
        "        structured_parts.append(f\"Feature 5: {bp5.group(1).strip()}\")\n",
        "    \n",
        "    if description:\n",
        "        structured_parts.append(f\"Description: {description.group(1).strip()}\")\n",
        "    \n",
        "    cleaned_text = \". \".join(structured_parts)\n",
        "    \n",
        "    full_text_cleaned = text.lower()\n",
        "    full_text_cleaned = re.sub(r\\'[^\\\\w\\\\s.,:\\\\-]\\', \\' \\', full_text_cleaned)\n",
        "    full_text_cleaned = re.sub(r\\'\\\\s+\\', \\' \\', full_text_cleaned)\n",
        "    full_text_cleaned = full_text_cleaned.strip()\n",
        "    \n",
        "    if cleaned_text and full_text_cleaned:\n",
        "        final_text = f\"{cleaned_text}. Full Details: {full_text_cleaned}\"\n",
        "    elif cleaned_text:\n",
        "        final_text = cleaned_text\n",
        "    else:\n",
        "        final_text = full_text_cleaned\n",
        "    \n",
        "    return final_text\n",
        "\n",
        "print(\"üöÄ Loading model with vLLM...\")\n",
        "llm = LLM(\n",
        "    model=\"granite_price_predictor_vllm\",\n",
        "    tensor_parallel_size=1,  # Adjust based on your GPU setup\n",
        "    max_model_len=2048,\n",
        "    gpu_memory_utilization=0.9,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "print(\"üìÇ Loading test data...\")\n",
        "test_df = pd.read_csv(\\'dataset/test.csv\\', encoding=\\'latin1\\')\n",
        "print(f\"Test data shape: {test_df.shape}\")\n",
        "\n",
        "# Clean text\n",
        "print(\"üßπ Cleaning text...\")\n",
        "test_df[\\'catalog_content\\'] = test_df[\\'catalog_content\\'].apply(clean_text_enhanced)\n",
        "\n",
        "# Create prompts\n",
        "print(\"üìù Creating prompts...\")\n",
        "prompts = [\n",
        "    f\"<|start_of_role|>user<|end_of_role|>Predict the price for this product: {text}<|end_of_text|>\\\\n<|start_of_role|>assistant<|end_of_role|>\"\n",
        "    for text in test_df[\\'catalog_content\\']\n",
        "]\n",
        "\n",
        "# Sampling parameters for deterministic output\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.1,\n",
        "    top_p=0.95,\n",
        "    max_tokens=64,\n",
        "    stop=[\"<|end_of_text|>\", \"\\\\n\\\\n\"]\n",
        ")\n",
        "\n",
        "print(f\"\\\\n‚ö° Generating predictions for {len(prompts)} samples with vLLM...\")\n",
        "print(\"This should be MUCH faster than one-by-one generation!\\\\n\")\n",
        "\n",
        "# Batch inference - THIS IS THE KEY!\n",
        "outputs = llm.generate(prompts, sampling_params)\n",
        "\n",
        "# Extract prices\n",
        "print(\"üí∞ Extracting prices from predictions...\")\n",
        "all_predictions = []\n",
        "\n",
        "for i, output in enumerate(tqdm(outputs, desc=\"Processing outputs\")):\n",
        "    predicted_text = output.outputs[0].text\n",
        "    \n",
        "    # Extract price from text\n",
        "    price_match = re.search(r\\'\\\\$(\\\\d+\\\\.?\\\\d*)|price is (\\\\d+\\\\.?\\\\d*)\\', predicted_text, re.IGNORECASE)\n",
        "    \n",
        "    if price_match:\n",
        "        price = float(price_match.group(1) or price_match.group(2))\n",
        "    else:\n",
        "        # Fallback\n",
        "        price = 50.0\n",
        "    \n",
        "    all_predictions.append(price)\n",
        "\n",
        "# Create submission\n",
        "print(\"\\\\nüíæ Creating submission file...\")\n",
        "submission = pd.DataFrame({\n",
        "    \\'sample_id\\': test_df[\\'sample_id\\'],\n",
        "    \\'price\\': all_predictions\n",
        "})\n",
        "\n",
        "submission.to_csv(\\'submission_granite_vllm.csv\\', index=False)\n",
        "\n",
        "print(f\"\\\\n‚úÖ Submission saved to submission_granite_vllm.csv\")\n",
        "print(f\"Shape: {submission.shape}\")\n",
        "print(f\"\\\\nPrice statistics:\")\n",
        "print(submission[\\'price\\'].describe())\n",
        "print(f\"\\\\nüéâ Done! Predictions completed in minutes instead of hours!\")\n",
        "'''\n",
        "\n",
        "# Save the script\n",
        "with open('vllm_inference.py', 'w') as f:\n",
        "    f.write(vllm_script)\n",
        "\n",
        "print(\"‚úÖ vLLM inference script saved to 'vllm_inference.py'\")\n",
        "print(\"\\nüìã To run fast inference:\")\n",
        "print(\"1. First, complete training and model saving (cells above)\")\n",
        "print(\"2. Install vLLM: pip install vllm\")\n",
        "print(\"3. Run: python vllm_inference.py\")\n",
        "print(\"\\n‚ö° This will generate predictions in MINUTES instead of 30+ hours!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upcOlWe7A1vc",
        "outputId": "8b74d486-1e03-474d-9779-9ece7ff66dc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('lora_model/tokenizer_config.json',\n",
              " 'lora_model/special_tokens_map.json',\n",
              " 'lora_model/chat_template.jinja',\n",
              " 'lora_model/vocab.json',\n",
              " 'lora_model/merges.txt',\n",
              " 'lora_model/added_tokens.json',\n",
              " 'lora_model/tokenizer.json')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save LoRA adapters first (lightweight backup)\n",
        "model.save_pretrained(\"lora_model\")\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "print(\"‚úÖ LoRA adapters saved to 'lora_model/'\")\n",
        "\n",
        "# IMPORTANT: Merge and save to 16-bit for vLLM inference\n",
        "print(\"\\nüîÑ Merging LoRA weights and saving for vLLM...\")\n",
        "print(\"This may take a few minutes...\")\n",
        "model.save_pretrained_merged(\"granite_price_predictor_vllm\", tokenizer, save_method=\"merged_16bit\")\n",
        "print(\"‚úÖ Model saved in vLLM-compatible format to 'granite_price_predictor_vllm/'\")\n",
        "print(\"\\n‚ö° Ready for fast batched inference with vLLM!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Fast Inference Strategy\n",
        "\n",
        "**Problem**: One-by-one predictions take 30+ hours for 75,000 samples ‚è∞\n",
        "\n",
        "**Solution**: Use vLLM for batched inference - takes only **5-10 minutes** on A100! ‚ö°\n",
        "\n",
        "### Plan:\n",
        "1. ‚úÖ Save model in vLLM-compatible format (merged 16-bit)\n",
        "2. ‚ö° Use vLLM to batch process ALL test samples at once\n",
        "3. üíæ Generate submission in minutes instead of hours\n",
        "\n",
        "Let's start by saving the model properly for vLLM:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install vLLM\n",
        "\n",
        "Now let's install vLLM for fast inference. This only needs to be done once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install vLLM for fast batched inference\n",
        "!pip install vllm -q\n",
        "print(\"‚úÖ vLLM installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üöÄ Fast Batched Inference with vLLM\n",
        "\n",
        "Now we'll use vLLM to process ALL 75,000 test samples in one go!\n",
        "\n",
        "**Why vLLM is fast:**\n",
        "- ‚ö° Batched processing (not one-by-one)\n",
        "- üß† PagedAttention for efficient memory\n",
        "- üî• Optimized CUDA kernels\n",
        "- üì¶ Continuous batching\n",
        "\n",
        "**Expected time on A100:** 5-10 minutes for full test set!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "\n",
        "print(\"üöÄ FAST BATCHED INFERENCE WITH vLLM\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load model with vLLM\n",
        "print(\"\\nüì¶ Loading model with vLLM...\")\n",
        "print(\"This will take a minute to initialize...\\n\")\n",
        "\n",
        "llm = LLM(\n",
        "    model=\"granite_price_predictor_vllm\",\n",
        "    tensor_parallel_size=1,  # Use 1 GPU, increase if you have multiple\n",
        "    max_model_len=2048,\n",
        "    gpu_memory_utilization=0.9,  # Use 90% of GPU memory\n",
        "    trust_remote_code=True,\n",
        "    dtype=\"float16\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model loaded successfully!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load test data\n",
        "print(\"üìÇ Loading test data...\")\n",
        "test_df = pd.read_csv('dataset/test.csv', encoding='latin1')\n",
        "print(f\"   Test samples: {len(test_df):,}\")\n",
        "\n",
        "# Apply same text cleaning\n",
        "print(\"\\nüßπ Cleaning text...\")\n",
        "test_df['catalog_content_cleaned'] = test_df['catalog_content'].apply(clean_text_enhanced)\n",
        "\n",
        "# Create prompts in Granite format\n",
        "print(\"\\nüìù Creating prompts...\")\n",
        "prompts = [\n",
        "    f\"<|start_of_role|>user<|end_of_role|>Predict the price for this product: {text}<|end_of_text|>\\n<|start_of_role|>assistant<|end_of_role|>\"\n",
        "    for text in test_df['catalog_content_cleaned']\n",
        "]\n",
        "\n",
        "print(f\"   Created {len(prompts):,} prompts\")\n",
        "print(f\"\\n‚úÖ Data prepared for inference\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sampling parameters\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.1,  # Low temperature for consistent outputs\n",
        "    top_p=0.95,\n",
        "    max_tokens=64,    # Enough for \"The predicted price is $XX.XX\"\n",
        "    stop=[\"<|end_of_text|>\", \"\\n\\n\"]  # Stop tokens\n",
        ")\n",
        "\n",
        "print(\"\\n‚ö° RUNNING BATCHED INFERENCE WITH vLLM\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Processing {len(prompts):,} samples...\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# THE KEY: Batched generation - processes ALL prompts efficiently!\n",
        "outputs = llm.generate(prompts, sampling_params, use_tqdm=True)\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "\n",
        "print(f\"\\n‚úÖ Inference complete!\")\n",
        "print(f\"   Total time: {total_time/60:.1f} minutes\")\n",
        "print(f\"   Speed: {len(prompts)/total_time:.1f} samples/second\")\n",
        "print(f\"\\nüéâ That's {30*60/total_time:.0f}x faster than one-by-one!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract prices from outputs\n",
        "print(\"\\nüí∞ Extracting prices from predictions...\")\n",
        "all_predictions = []\n",
        "\n",
        "for output in tqdm(outputs, desc=\"Processing outputs\"):\n",
        "    predicted_text = output.outputs[0].text\n",
        "    \n",
        "    # Extract price from text (patterns: $XX.XX or \"price is XX.XX\")\n",
        "    price_match = re.search(r'\\$(\\d+\\.?\\d*)|price is (\\d+\\.?\\d*)|predicted price is (\\d+\\.?\\d*)', \n",
        "                           predicted_text, re.IGNORECASE)\n",
        "    \n",
        "    if price_match:\n",
        "        # Get the first non-None group\n",
        "        price = float([g for g in price_match.groups() if g is not None][0])\n",
        "    else:\n",
        "        # Fallback to median price if parsing fails\n",
        "        price = 50.0\n",
        "    \n",
        "    # Ensure reasonable price range\n",
        "    price = np.clip(price, 0.01, 10000.0)\n",
        "    all_predictions.append(price)\n",
        "\n",
        "print(f\"‚úÖ Extracted {len(all_predictions):,} prices\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create submission DataFrame\n",
        "print(\"\\nüìä Creating submission DataFrame...\")\n",
        "submission = pd.DataFrame({\n",
        "    'sample_id': test_df['sample_id'],\n",
        "    'price': all_predictions\n",
        "})\n",
        "\n",
        "# Save submission\n",
        "submission_file = 'submission_granite_vllm.csv'\n",
        "submission.to_csv(submission_file, index=False)\n",
        "\n",
        "print(f\"\\n‚úÖ Submission saved to: {submission_file}\")\n",
        "print(f\"   Shape: {submission.shape}\")\n",
        "print(f\"\\nüìà Price Statistics:\")\n",
        "print(submission['price'].describe())\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ FAST INFERENCE COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Generated {len(submission):,} predictions in {total_time/60:.1f} minutes\")\n",
        "print(f\"Average: {total_time/len(submission):.3f} seconds per sample\")\n",
        "print(\"\\nüöÄ Ready for submission!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üîç Optional: Inspect Sample Predictions\n",
        "\n",
        "Let's look at a few predictions to verify they make sense:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show 5 random samples\n",
        "import random\n",
        "\n",
        "print(\"Sample Predictions:\\n\" + \"=\"*80)\n",
        "\n",
        "for i in random.sample(range(len(test_df)), min(5, len(test_df))):\n",
        "    print(f\"\\nSample ID: {test_df.iloc[i]['sample_id']}\")\n",
        "    print(f\"Catalog (first 150 chars): {test_df.iloc[i]['catalog_content'][:150]}...\")\n",
        "    print(f\"Cleaned text (first 150 chars): {test_df.iloc[i]['catalog_content_cleaned'][:150]}...\")\n",
        "    print(f\"Model output: {outputs[i].outputs[0].text}\")\n",
        "    print(f\"Extracted price: ${all_predictions[i]:.2f}\")\n",
        "    print(\"-\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üõë STOP HERE FOR FAST INFERENCE! üõë\n",
        "\n",
        "‚úÖ Your model is now saved and ready for fast inference!\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "**DO NOT run one-by-one predictions in this notebook** (it will take 30+ hours!)\n",
        "\n",
        "**Instead:**\n",
        "\n",
        "1. ‚úÖ Close this notebook (training is complete)\n",
        "2. üöÄ Run the fast vLLM inference script:\n",
        "   ```bash\n",
        "   python vllm_fast_inference.py\n",
        "   ```\n",
        "3. ‚è±Ô∏è Get predictions in **5-10 minutes** instead of 30+ hours!\n",
        "\n",
        "**Read the guide:** `VLLM_INFERENCE_GUIDE.md`\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKX_XKs_BNZR"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = 2048,\n",
        "        load_in_4bit = True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHjt_SMYsd3P"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False:\n",
        "    model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: # Pushing to HF Hub\n",
        "    model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False:\n",
        "    model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: # Pushing to HF Hub\n",
        "    model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False:\n",
        "    model.save_pretrained(\"model\")\n",
        "    tokenizer.save_pretrained(\"model\")\n",
        "if False: # Pushing to HF Hub\n",
        "    model.push_to_hub(\"hf/model\", token = \"\")\n",
        "    tokenizer.push_to_hub(\"hf/model\", token = \"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv4vXHd61i7"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q974YEVPI7JS"
      },
      "source": [
        "Likewise, if you want to instead push to GGUF to your Hugging Face account, set `if False` to `if True` and add your Hugging Face token and upload location!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgcJIhJ0I_es"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False:\n",
        "    model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False:\n",
        "    model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: # Pushing to HF Hub\n",
        "    model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False:\n",
        "    model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: # Pushing to HF Hub\n",
        "    model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzmjlc3gzJVs"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp.\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Train your own reasoning model - Llama GRPO notebook [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ‚≠êÔ∏è <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠êÔ∏è\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0759e398938a4095ba9af12b9ccad04d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "087930aaf9674d23adb19fb41ca3d78b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0acfdad4a12a433f9084930d2903a4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb63137aa20041759b8f2db481107170",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2f4909b235b648c0942daaa1ae2d84f3",
            "value": "‚Äá504/504‚Äá[00:00&lt;00:00,‚Äá5262.29‚Äáexamples/s]"
          }
        },
        "0e91915212da4b699568b2931b2563c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fc8224771044c749e66770d939ca1cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "107ed420bf174d149ff7b64dd1d15c43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11bbc91e0e9d4164978a147fc4b8ce68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18f56a4308634623afb95428a54edd0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "191b6a8100e84d9a939e11ee81de4a83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2596a30288044233923b390c0703b5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b6eb0208d664e79be39927c02788eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d2bf2089a4343fcbce758086e216f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f4909b235b648c0942daaa1ae2d84f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3749d01cb5834e479232b55150dc024e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38731ca21c514685bd6db34cca54b56f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d728fdd8eb24ed09a0ea06e58db01e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48169ddbaf7649b88594e8d110854b35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b73f84a06754e5d8fc832e20a693695": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "551ee4eac5bc455b93b1d0bab7a229c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7faeab15e0346e696d35d130a070d47",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0d6a5c340d749479c1d94adf17bb981",
            "value": 1
          }
        },
        "62f3983a614f4566ad043a3de97a7114": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_107ed420bf174d149ff7b64dd1d15c43",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e709b2fe6ad541579acaa430c862fb3f",
            "value": "Map‚Äá(num_proc=2):‚Äá100%"
          }
        },
        "66cc062d92924dbc9d91896352347e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b73f84a06754e5d8fc832e20a693695",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fa69243ce6de4eafbcdb7c34a23ee5b5",
            "value": "‚Äá504/504‚Äá[00:04&lt;00:00,‚Äá151.17‚Äáexamples/s]"
          }
        },
        "67cd1b3132444520a8794adfcc44c223": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7216e702e8ec4305a386b5447e468ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc8739e60d6844669a51a137c48a6218",
              "IPY_MODEL_b346d68403ee499b9070ee974c5e05e5",
              "IPY_MODEL_86082ed4f0824faa9b996047a28a4525"
            ],
            "layout": "IPY_MODEL_48169ddbaf7649b88594e8d110854b35"
          }
        },
        "74de35f7e7824f39abb1a7dd37ab8669": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c9936cd3bbf430bbcf69f7a2648e716": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce4aa788f8ca48ab81305e428e174374",
              "IPY_MODEL_ecb7209ff3bb45f89a59e84972e5d978",
              "IPY_MODEL_dd17c05cc47949ec85d5e43903ab7ae0"
            ],
            "layout": "IPY_MODEL_191b6a8100e84d9a939e11ee81de4a83"
          }
        },
        "86082ed4f0824faa9b996047a28a4525": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9481dda959ee4436b42e8c6c923231d0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8bf2866db80d4a5797b6f9edceea1a67",
            "value": "‚Äá1.04M/1.04M‚Äá[00:00&lt;00:00,‚Äá15.5MB/s]"
          }
        },
        "8bf2866db80d4a5797b6f9edceea1a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8daa961157694497a8ca1bb1c4bcff0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "909fb7562ae64dca9c888e00b2f7f881": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62f3983a614f4566ad043a3de97a7114",
              "IPY_MODEL_9de4b3e3ec324af8be09fcc99c35a7f9",
              "IPY_MODEL_c17629fa71064480a2283c94b3fa0951"
            ],
            "layout": "IPY_MODEL_11bbc91e0e9d4164978a147fc4b8ce68"
          }
        },
        "91f0a47939ff4891808591fa9df9ce6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9481dda959ee4436b42e8c6c923231d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96334dca3a004ddeae99af2304c25b30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c854d05981044279ea79792ce50c64f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d1f73c83e6b4856b2c5d4039eb2a75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3749d01cb5834e479232b55150dc024e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0fc8224771044c749e66770d939ca1cd",
            "value": "Map:‚Äá100%"
          }
        },
        "9de4b3e3ec324af8be09fcc99c35a7f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b02287b961634d719ee3e4fade474c47",
            "max": 504,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a522c6b18f9744259851fe33a88705bf",
            "value": 504
          }
        },
        "9de6933d0e0d432cb8121c63d287053a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7777936dc2e41568bc2649bb02a763b",
              "IPY_MODEL_551ee4eac5bc455b93b1d0bab7a229c4",
              "IPY_MODEL_fbdf439f327f4ceb8c24360ff66abe6b"
            ],
            "layout": "IPY_MODEL_38731ca21c514685bd6db34cca54b56f"
          }
        },
        "a17bf82d1ad9468dbdbad8038f4715cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a522c6b18f9744259851fe33a88705bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a58e7b92da104470959e2e2cb8439c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f129ebb055724b73b4017f0396389cca",
            "max": 504,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18f56a4308634623afb95428a54edd0f",
            "value": 504
          }
        },
        "b02287b961634d719ee3e4fade474c47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b26644a0095d43bb975c5443d51233e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b346d68403ee499b9070ee974c5e05e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67cd1b3132444520a8794adfcc44c223",
            "max": 1035309,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0759e398938a4095ba9af12b9ccad04d",
            "value": 1035309
          }
        },
        "b9f552bcbccf42dca02a5ccdfd5eb871": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb63137aa20041759b8f2db481107170": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0ee71d150f648ceb740af021342dc88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc5da287b7d247388674d53317ed8864",
              "IPY_MODEL_a58e7b92da104470959e2e2cb8439c3b",
              "IPY_MODEL_66cc062d92924dbc9d91896352347e34"
            ],
            "layout": "IPY_MODEL_9c854d05981044279ea79792ce50c64f"
          }
        },
        "c17629fa71064480a2283c94b3fa0951": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74de35f7e7824f39abb1a7dd37ab8669",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_91f0a47939ff4891808591fa9df9ce6c",
            "value": "‚Äá504/504‚Äá[00:00&lt;00:00,‚Äá1000.60‚Äáexamples/s]"
          }
        },
        "c7777936dc2e41568bc2649bb02a763b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a17bf82d1ad9468dbdbad8038f4715cc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2d2bf2089a4343fcbce758086e216f34",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá"
          }
        },
        "c9da52df017244ab8d0767fc6b091996": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cab523c6b34d48af9d6f52c62ff64a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc5da287b7d247388674d53317ed8864": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96334dca3a004ddeae99af2304c25b30",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8daa961157694497a8ca1bb1c4bcff0b",
            "value": "Unsloth:‚ÄáTokenizing‚Äá[&quot;text&quot;]‚Äá(num_proc=6):‚Äá100%"
          }
        },
        "ccc811b8517e4b568a91ae9d24131512": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce4aa788f8ca48ab81305e428e174374": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fea9c1a564d1482fbb2d4c9db0249bfa",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cfd5bf250f334e19b8cc1bc217bf33f7",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "cfd5bf250f334e19b8cc1bc217bf33f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7faeab15e0346e696d35d130a070d47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "dd17c05cc47949ec85d5e43903ab7ae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9da52df017244ab8d0767fc6b091996",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ccc811b8517e4b568a91ae9d24131512",
            "value": "‚Äá2/2‚Äá[00:24&lt;00:00,‚Äá11.00s/it]"
          }
        },
        "e0d6a5c340d749479c1d94adf17bb981": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e709b2fe6ad541579acaa430c862fb3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecb7209ff3bb45f89a59e84972e5d978": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff5cb7e5b5e24fdc9ca6ecaa43e1ae10",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b26644a0095d43bb975c5443d51233e4",
            "value": 2
          }
        },
        "f129ebb055724b73b4017f0396389cca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa69243ce6de4eafbcdb7c34a23ee5b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbdf439f327f4ceb8c24360ff66abe6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9f552bcbccf42dca02a5ccdfd5eb871",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2b6eb0208d664e79be39927c02788eed",
            "value": "‚Äá504/0‚Äá[00:00&lt;00:00,‚Äá3719.61‚Äáexamples/s]"
          }
        },
        "fc8739e60d6844669a51a137c48a6218": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d728fdd8eb24ed09a0ea06e58db01e3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cab523c6b34d48af9d6f52c62ff64a64",
            "value": "Downloading‚Äádata:‚Äá100%"
          }
        },
        "fea9c1a564d1482fbb2d4c9db0249bfa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feffcb8924db4212b95fba1dac496a8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d1f73c83e6b4856b2c5d4039eb2a75c",
              "IPY_MODEL_ff1f74f1b8434a9388adfbb77a0bec8f",
              "IPY_MODEL_0acfdad4a12a433f9084930d2903a4c7"
            ],
            "layout": "IPY_MODEL_0e91915212da4b699568b2931b2563c1"
          }
        },
        "ff1f74f1b8434a9388adfbb77a0bec8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_087930aaf9674d23adb19fb41ca3d78b",
            "max": 504,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2596a30288044233923b390c0703b5de",
            "value": 504
          }
        },
        "ff5cb7e5b5e24fdc9ca6ecaa43e1ae10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
